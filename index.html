---
layout: single
author_profile: true
---

<h2>About Me</h2>
<p>
I'm currently a research assistant in the Deborah Marks Lab at Harvard Medical School, working on applying machine 
learning methods to problems in biological sequence modeling. Previouly, I received my master's in computer science 
from the University of Oxford, and before that studied computer science and political science at Brown University. 
I'm broadly interested in questions of interpretability and explainability in machine learning. This ranges from technical 
questions, such as how we generate different kinds of explanations, to more social scientific or public policy 
ones (how useful are different interpretability techniques in practice?, how do we incentivize the development of 
interpretable ML applications?, etc.).
</p>

<h2>Projects</h2>
<h3>Assessing the Interpretability of Large Language Models</h3>
<p>
For my master's dissertation, I evaluated the quality of different black-box interpretability methods when applied 
across a range of different large language models. This involved applying several previously published frameworks for 
assessing the quality of model interpretations to many new models and methods, extending their beyond the smaller models 
often studied in the initial publications of these frameworks. This project was supervised by Yarin Gal, with help from 
Lisa Schut, Andrew Jesson, and Been Kim. The full text of my dissertation is available <a href="/assets/pdfs/msc_thesis.pdf">here</a>.
</p>
<h3>Multiagent Planning via Partial Coordination in Markov Games</h3>
<p>
This project was my senior honors thesis, supervised by Michael Littman and Mark Ho, and focused on
finding methods for scaling multiagent planning algorithms in markov games. Learning and planning algorithms 
in markov games tend to scale very poorly as you increase the number of agents in the game. To avoid this, we 
proposed a 'model game' framework, in which each agent has a simplified internal model of the environment, and 
computes a plan using that model. A pdf of my thesis can be found <a href=/assets/pdfs/thesis.pdf>here</a>.</p>
<h3>DeepLTLf: Learning Finite Linear Temporal Logic Specifications with a Specialized Neural Operator</h3>
<p>
This project was focused on the problem of learning linear temporal logic formulae from example temporal traces. 
We devised a specialized neural network architecture to learn LTL operators that could scale well beyond previous 
SAT-based approaches and handle noisy data more robustly. A copy of the resulting paper can be found 
<a href=https://arxiv.org/abs/2111.04147>here</a>.
</p>

<h2>Links</h2>
<ul>
    <li><a href="/assets/pdfs/resume.pdf">Resume</a></li>
    <li><a href="https://github.com/danieldritter">Github</a></li>
    </ul>
