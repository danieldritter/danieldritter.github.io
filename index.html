---
layout: single
author_profile: true
---

<h2>About Me</h2>
<p>
I'm currently working as a software engineer in the Debora Marks Lab at Harvard Medical School, applying machine 
learning methods to problems in biological sequence modeling. Previously, I received my master's in computer science 
from the University of Oxford, and before that studied computer science and political science at Brown University. I'm broadly interested in 
developing methods for making the behavior of deep sequence models (like protein or natural large language models) more controllable and interpretable. Additionally,
I want to use these methods to make sequence models more safe, e.g. by reducing issues like bias and unfairness, and to extract information from their internal representations 
that may be useful for human understanding. 
<br/>  
</p>

<h2>Publications</h2>
<b>ProteinGym: Large-Scale Benchmarks for Protein Fitness Prediction and Design</b>
<br/>
<b>Daniel Ritter*</b>, Pascal Notin*, Lood Van Niekerk*, Aaron W Kollasch*, Steffanie Paul, Han Spinner, Nathan J. Rollins, Ada Shaw, Rose Orenbuch, Ruben Weitzman, Jonathan Frazer, Mafalda Dias, Dinko Franceschi, Yarin Gal, Debora S. Marks
<br/>
<i>NeurIPS, 2023</i>
<br/>
[<a href="https://www.proteingym.org/">link</a>]
<br/>
<b>Learning from prepandemic data to forecast viral escape</b>
<br/>
Nicole N. Thadani*, Sarah Gurev*, Pascal Notin*, Noor Youssef, Nathan J. Rollins, <b>Daniel Ritter</b>, Chris Sander, Yarin Gal, Debora S. Marks.
<br/>
<i>Nature, 2023</i>
<br/>
[<a href="https://www.nature.com/articles/s41586-023-06617-0">link</a>]
<br/>
<br/>
<b>TranceptEVE: Combining family-specific and family-agnostic models of protein sequences for improved fitness prediction</b>
<br/>
Pascal Notin, Lood Van Niekerk, Aaron W Kollasch, <b>Daniel Ritter</b>, Yarin Gal, Debora S. Marks
<br/>
<i>NeurIPS Learning Meaningful Representations of Life Workshop, 2022</i>
<br/>
[<a href="https://www.biorxiv.org/content/10.1101/2022.12.07.519495v1.full.pdf">link</a>]
<br/>
<br/>
<b>Assessing the Interpretability of Large Language Models</b>
<br/>
<b>Daniel Ritter</b>, Lisa Schut, Andrew Jesson, Been Kim, Yarin Gal
<br/>
<i>Master's Thesis, 2022</i>
<br/>
[<a href="/assets/pdfs/msc_thesis.pdf">link</a>]
<br/>
<br/>
<b>Multiagent Planning via Partial Coordination in Markov Games</b>
<br/>
<b>Daniel Ritter</b>, Mark Ho, Michael Littman
<br/>
<i>Undergraduate Honor's Thesis, 2021</i>
<br/>
[<a href="/assets/pdfs/thesis.pdf">link</a>]
<br/>
<br/>
<b>DeepLTLf: Learning Finite Linear Temporal Logic Specifications with a Specialized Neural Operator</b>
<br/>
Homer Walke, <b>Daniel Ritter</b>, Carl Trimbach, Michael Littman
<br/>
<i>Arxiv preprint, 2021</i>
<br/>
[<a href="https://arxiv.org/abs/2111.04147">link</a>]
<br/>
<br/>
<p>*Equal author contribution</p>

<h2>Other Links</h2>
<ul>
    <li><a href="/assets/pdfs/resume.pdf">Resume</a></li>
    <li><a href="https://github.com/danieldritter">Github</a></li>
    </ul>
