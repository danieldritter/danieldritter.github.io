---
layout: single
author_profile: true
---

<h2>About Me</h2>
<p>I'm currently a master's student studying computer science at the University of Oxford.
    Previously, I studied computer science and political science at Brown University (class of 2021).
    I'm broadly interested in questions of interpretability and explainability in machine learning, and
    particularly in interpretability in natural language and reinforcement learning contexts.
    From a less technical perspective, I'm also very interested in policy questions around the development
    of ML applications, and how we can incentivize and ensure the development of more robust and interpretable
    ML models.
</p>

<h2>Projects</h2>
<h3>Multiagent Planning via Partial Coordination in Markov Games</h3>
<p>This project was my senior honors thesis, supervised by Michael Littman and Mark Ho, and focused on finding methods for scaling multiagent planning algorithms in markov games. Learning and planning algorithms in markov games tend to scale very poorly as you increase the number of agents in the game. To avoid this, we proposed a 'model game' framework, in which each agent has a simplified internal model of the environment, and computes a plan using that model. A pdf of my thesis can be found <a href=/assets/pdfs/thesis.pdf>here</a>.</p>
<h3>DeepLTLf: Learning Finite Linear Temporal Logic Specifications with a Specialized Neural Operator</h3>
<p>This project was focused on the problem of learning linear temporal logic formulae from example temporal traces. We devised a specialized neural network architecture to learn LTL operators that could scale well beyond previous SAT-based approaches and handle noisy data more robustly. A copy of the resulting paper can be found <a href=https://arxiv.org/abs/2111.04147>here</a>.</p>

<h2>Links</h2>
<ul>
    <li><a href="/assets/pdfs/resume.pdf">Resume</a></li>
    <li><a href="https://github.com/danieldritter">Github</a></li>
    </ul>
